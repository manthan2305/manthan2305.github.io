<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://manthan2305.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://manthan2305.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-27T16:48:17+00:00</updated><id>https://manthan2305.github.io/feed.xml</id><title type="html">Manthan Solanki</title><subtitle>Computer Science Graduate at Stuttgart University, passionate about Artificial Intelligence and Machine Learning. </subtitle><entry><title type="html">The Compositional Leap - Generative AI in Inverse Design Innovation</title><link href="https://manthan2305.github.io/blog/2025/cindm/" rel="alternate" type="text/html" title="The Compositional Leap - Generative AI in Inverse Design Innovation"/><published>2025-02-10T00:00:00+00:00</published><updated>2025-02-10T00:00:00+00:00</updated><id>https://manthan2305.github.io/blog/2025/cindm</id><content type="html" xml:base="https://manthan2305.github.io/blog/2025/cindm/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Inverse Design is a paradigm-shifting approach that reimagines traditional optimization. Instead of iteratively refining a system toward a desired outcome, it starts with the end goal itself — a predefined objective — and works backward to computationally derive optimal configurations. This outcome-driven methodology fundamentally reverses the conventional design workflow, prioritizing target specifications over incremental adjustments. For example, in material discovery <d-cite key="zunger2024inverse"></d-cite>, instead of starting with a material and calculate its properties, you start with the desired property (like a specific band gap or temperature behavior) and work backward to find or design the material that fits.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/example-image-480.webp 480w,/assets/img/2025-02-10-cindm/example-image-800.webp 800w,/assets/img/2025-02-10-cindm/example-image-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/example-image.png" class="example-image" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 1 Inverse design example</figcaption> </figure> <p>The applications of Inverse Design span many domains, including:</p> <ul> <li><strong>Aerodynamics</strong>: Designs plane shapes to minimize drag by simulating air-fluid dynamics and boundary interactions<d-cite key="athanasopoulos2009drag"></d-cite>.</li> <li><strong>Underwater Robotics</strong>: Optimizes robot shapes for reduced drag, energy efficiency, maneuverability, and acoustic performance<d-cite key="saghafi2020underwater"></d-cite>.</li> <li><strong>Nanophotonics</strong>: Creates micro- and nano-scale structures for precise light interactions in lasers, data storage, chips, and solar cells<d-cite key="molesky2018nanophotonics"></d-cite>.</li> <li><strong>Battery Design</strong>: Enables efficient battery interphases and optimizes charging protocols for high-performance<d-cite key="bhowmik2019battery"></d-cite>, long-life lithium-ion batteries<d-cite key="attia2020hyperparameter"></d-cite>.</li> </ul> <p>However, inverse design faces challenges related to computational speed due to intensive conventional modeling and optimization, as well as navigating complex, hierarchical, and heterogeneous design spaces. This is especially true for intricate systems, such as rocket designs.</p> <p>Recent advancements in Generative Artificial Intelligence have opened up new possibilities for solving these problems more efficiently and accurately. AI models can explore high-dimensional spaces, providing unique solutions. However, backpropagation-based inverse design methods, such as the one introduced by Allen et al. <d-cite key="allen2022inverse"></d-cite>, rely on surrogate models that often suffer from adversarial design modes, where the inferred design parameters are not physically plausible despite excellent optimization performance. The method proposed by Wu et al. <d-cite key="wu2024compositional"></d-cite> addresses this issue using compositional diffusion models, which optimize over a learned energy function, improving design stability and generalization.</p> <p>The background section briefly explains the inverse design problem, followed by a discussion of the <em>Compositional Generative Inverse Design</em> by Wu et al.</p> <h2 id="background">Background</h2> <h3 id="the-need-of-partial-differential-equations-pdes">The need of Partial Differential Equations (PDEs)</h3> <p>In design optimization, PDEs serve as constraints that ensure the designed system adheres to the governing physical laws. By incorporating PDE constraints, we can accurately predict system behavior under different conditions, leading to designs that are both efficient and feasible. This approach is prevalent in fields like aerodynamics, where optimizing shapes for minimal drag requires solving PDEs that describe fluid flow.</p> <h4 id="the-basics-of-pdes">The Basics of PDEs</h4> <p>A Partial Differential Equation (PDE) is a mathematical equation involving an unknown function with several variables and their partial derivatives with respect to independent variables <d-cite key="quarteroni2008numerical"></d-cite>.</p> <p>Formally, a PDE can be written as:</p> \[F \left(x_1, x_2, ..., x_n, u, \frac{\partial u}{\partial x_1}, \frac{\partial u}{\partial x_2}, ..., \frac{\partial^2 u}{\partial x_1^2}, \frac{\partial^2 u}{\partial x_1 \partial x_2}, ... \right) = 0,\] <p>where \(u = u(x_1, x_2, ..., x_n)\) is the unknown function, and \(F\) is a given function.</p> <h4 id="classical-numerical-methods-for-solving-pdes">Classical Numerical Methods for Solving PDEs</h4> <p>Traditional numerical techniques, such as the <strong>Finite Element Method (FEM)</strong> and the <strong>Finite Difference Method (FDM)</strong>, have been the cornerstone of PDE solvers <d-cite key="ferziger2001fdm"></d-cite>. These methods approximate the solution of a PDE by discretizing the spatial domain, converting the continuous problem into a solvable system of equations.</p> <ul> <li><strong>Finite Difference Method (FDM)</strong>: A grid-based technique that discretizes the spatial domain into a structured mesh and approximates derivatives using finite difference approximations (e.g., forward, backward, or central differences). It is particularly useful for problems where structured grids align well with the computational domain.</li> <li><strong>Finite Element Method (FEM)</strong>: Unlike FDM, FEM divides the domain into smaller, simpler elements (such as triangles or quadrilaterals) and represents the solution using basis functions. This method is especially useful for complex geometries where structured grids may not be efficient.</li> </ul> <p>Numerical solvers discretize the continuous spatial and temporal domains into a finite set of points to approximate solutions. Two widely used approaches for domain discretization are:</p> <ol> <li> <p><strong>Eulerian Scheme</strong>: A fixed-grid approach that is commonly used in <strong>finite difference methods</strong> for solving PDEs. The spatial domain is discretized into a structured grid, and differential operators are replaced by numerical approximations. For example, a forward difference approximation for a spatial derivative is:</p> \[\frac{\partial u}{\partial x} (x, t) \approx \frac{u(x + \Delta x, t) - u(x,t)}{\Delta x},\] <p>where \(\Delta x\) represents spatial grid spacing and \(x + \Delta x\) are points on the computational mesh. This approach is efficient for structured problems but struggles with deformable geometries.</p> </li> <li> <p><strong>Lagrangian Scheme</strong>: A <strong>finite element-based approach</strong> that tracks individual points (particles) as they move through the domain. This method is particularly useful for problems where the computational domain deforms over time, such as fluid dynamics and material simulations. A well-known example is <strong>Smoothed Particle Hydrodynamics (SPH)</strong> <d-cite key="monaghan1992sph"></d-cite>, which approximates fluid behavior using a set of discrete particles. However, SPH and other Lagrangian methods can suffer from challenges like particle clumping and numerical instability.</p> </li> </ol> <h4 id="limitations-of-classical-numerical-methods">Limitations of Classical Numerical Methods</h4> <p>Despite their effectiveness, classical numerical methods suffer from several limitations:</p> <ul> <li><strong>High accuracy but low efficiency</strong>: While these methods provide precise solutions, they are computationally expensive, making them impractical for real-time or large-scale applications.</li> <li><strong>Need for rich expert knowledge</strong>: Implementing and tuning numerical solvers require deep expertise in numerical analysis, discretization techniques, and domain-specific PDE formulations, making them less accessible.</li> <li><strong>Difficulty in handling high-dimensional design spaces</strong>: Many real-world problems involve complex, high-dimensional parameter spaces, where traditional numerical methods struggle due to the curse of dimensionality and the need for fine discretization.</li> </ul> <h4 id="time-stepping-methods">Time-Stepping Methods</h4> <p>To solve <strong>dynamic PDEs</strong>, numerical solvers combine time-stepping methods with the previously discussed spatial discretization approaches <d-cite key="ascher1995time"></d-cite>. These methods advance solutions in time while ensuring stability and accuracy.</p> <ul> <li> <p><strong>Explicit Methods</strong>: Directly compute the future state using known values. A common example is the forward Euler method:</p> \[u_{t+\Delta t} \approx u_t + \Delta t \partial_t u.\] <p>While simple and computationally efficient, explicit methods require small time steps to maintain stability, especially for stiff PDEs.</p> </li> <li> <p><strong>Implicit Methods</strong>: Solve equations involving both the current and future states, allowing for larger, stable time steps. However, they require iterative solvers, increasing computational cost. Implicit methods are preferred for problems with strict stability constraints, such as fluid dynamics and structural mechanics.</p> </li> </ul> <p>Due to the <strong>computational challenges, expert knowledge requirements, and scalability issues</strong> of classical numerical methods, researchers have explored alternative approaches. Recent advancements in <strong>deep learning-based generative models</strong> offer promising solutions, enabling efficient and scalable PDE solvers without the traditional constraints.</p> <h3 id="neural-pde-solvers">Neural PDE Solvers</h3> <p>Deep Learning-based PDE solvers <d-cite key="butler2021artificial"></d-cite> significantly outperform classical numerical methods in terms of speed, scalability, and adaptability. Neural solvers can generalize across conditions, adapt to tasks, and learn directly from data, making them particularly valuable for complex or uncertain systems. They allow for larger time steps, most are meshless, and leverage GPUs efficiently.</p> <h4 id="problem-setup">Problem Setup</h4> <p>Time-evolving PDEs describe how a system changes over space and time:</p> \[\partial_t u + \mathcal D (x, t, u, \partial_x u, \partial_{xx}u,...) = 0 \quad (x, t) \in U,\] \[u(x, 0) = u_0(x) \quad x \in \mathbb{X},\] \[\mathcal{B}u(x, t) = 0 \quad (x, t) \in \partial \mathbb{X} \times \mathbb{T},\] <p>where:</p> <ul> <li>\(u(x, t)\) is the unknown function (solution) over space (\(\mathbb{X}\)) and time (\(\mathbb{T}\)),</li> <li>\(D\) is the differential operator relating derivatives of \(u\),</li> <li>\(u_0\) is the initial condition at \(t = 0\),</li> <li>\(B\) represents the boundary condition on the spatial domain’s boundary (\(\partial \mathbb{X}\)).</li> </ul> <p>The goal is to find \(u(x, t;\gamma)\) that satisfies these equations, where \(\gamma\) defines the problem setup (initial, boundary condition, and parameters). The objective function \(\mathcal{J}\) measures the quality of the design:</p> \[\dot\gamma = \underset{\dot\gamma}{\arg\min}\, \mathbb{E}_{x,t}[\mathcal{J}(u(x, t; \hat\gamma))]\] <h4 id="deep-learning-based-inverse-design">Deep Learning-Based Inverse Design</h4> <p>Recent advancements in machine learning have introduced innovative methods for solving <strong>inverse design problems</strong> in fluid-structure interactions and other physical systems. A notable approach is presented in the paper <em>Physical Design Using Differentiable Learned Simulators</em> by Allen et al. (2022) <d-cite key="allen2022inverse"></d-cite>. This method leverages <strong>graph neural network (GNN) simulators</strong> combined with <strong>gradient-based optimization</strong> to predict the physical dynamics and optimize design parameters.</p> <h5 id="method-overview">Method Overview</h5> <p>The figure below outlines the method’s pipeline:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/allen_2022_model-480.webp 480w,/assets/img/2025-02-10-cindm/allen_2022_model-800.webp 800w,/assets/img/2025-02-10-cindm/allen_2022_model-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/allen_2022_model.png" class="allen-2022" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 2 Inverse designing with neural surrogate model</figcaption> </figure> <ol> <li> <p><strong>Surrogate Forward Model</strong>:<br/> A learned forward model, denoted as \(f_\theta\), is trained to autoregressively predict the system’s dynamics over time. Given the initial state \(u^0\) and the design parameters \(\gamma\), the model predicts the subsequent states \(u^1, u^2, ..., u^T\). This forward pass mimics the physical process being simulated.</p> </li> <li> <p><strong>Optimization via Backpropagation</strong>:<br/> Using the predicted dynamics \(U_{[0,T]}(\gamma)\), the method evaluates an objective function \(J(U_{[0,T]}(\gamma), \gamma)\). The objective is optimized with respect to the design parameters \(\gamma\) using backpropagation through time (BPTT). This enables efficient gradient-based updates, allowing the model to adjust \(\gamma\) to achieve the desired target dynamics or design outcomes.</p> </li> </ol> <h5 id="challenges">Challenges</h5> <p>A significant challenge with these models is the risk of <strong>over-optimization</strong>. This occurs when the optimization process exploits inaccuracies in the surrogate model, leading to design parameters that appear optimal within the model but perform poorly in reality—a phenomenon known as <strong>adversarial design parameters</strong> <d-cite key="zhao2022generating"></d-cite>. The root cause of this issue is that surrogate models typically lack a measure of data likelihood and cannot discern whether design parameters are within the distribution of the training data. Consequently, optimization can easily venture into regions outside the training distribution, resulting in designs that the surrogate model cannot accurately predict. This limitation underscores the need for methods that can account for data likelihood and maintain optimization within the bounds of the training distribution to ensure reliable performance.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/adversarial-modes-480.webp 480w,/assets/img/2025-02-10-cindm/adversarial-modes-800.webp 800w,/assets/img/2025-02-10-cindm/adversarial-modes-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/adversarial-modes.png" class="admodes" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 3 Adversarial modes</figcaption> </figure> <h4 id="compositional-models">Compositional Models</h4> <p>Compositional models are frameworks that solve complex tasks by decomposing them into smaller, interpretable subtasks, each handled by specialized sub-models. These sub-models are designed to represent distinct concepts, skills, or physical principles, and their outputs are combined—either sequentially or hierarchically—to produce a unified solution. This approach mirrors how humans solve problems by breaking them into modular steps (e.g., “build a chair” → design legs, seat, backrest → assemble parts).</p> <h5 id="example-composable-diffusion-models">Example: Composable Diffusion Models</h5> <p>A seminal example is Compositional Visual Generation with Composable Diffusion Models by Liu et al. <d-cite key="liu2022compositional"></d-cite>. Here, individual diffusion models are trained to represent specific visual concepts (e.g., objects, textures, spatial relationships).</p> <h5 id="applications-beyond-vision">Applications Beyond Vision</h5> <p>In 3D synthesis<d-cite key="po2023synthesis"></d-cite>, separate models handle geometry, material properties, and physics constraints.</p> <p>For trajectory planning<d-cite key="du2019trajectory,urain2021planning"></d-cite>, sub-models manage obstacle avoidance, dynamic constraints, and energy efficiency.</p> <p>In hierarchical decision-making<d-cite key="ajay2023decision"></d-cite>, compositionality enables high-level task decomposition (e.g., “grasp object” → plan arm motion, adjust gripper force).</p> <h2 id="compositional-inverse-design-using-diffusion-models-cindm">Compositional Inverse Design using Diffusion Models (CinDM)</h2> <p>Wu et al. reimagine inverse design through the lens of diffusion processes, merging the flexibility of compositional energy optimization with the generative power of probabilistic models. Their framework, CinDM, reframes design generation as a guided stochastic exploration of high-dimensional solution spaces, where constraints and objectives act as dynamic sculptors of the diffusion trajectory.</p> <h3 id="main-contribution">Main contribution:</h3> <ul> <li> <p><strong>Novel Inverse Design Formulation</strong>: Inverse design is treated as an energy optimization problem, enabling flexible and efficient design generation.</p> </li> <li> <p><strong>CinDM</strong>: Compositional Inverse Design with Diffusion Models, which generalizes to complex and out-of-distribution inputs beyond the training set.</p> </li> </ul> <h3 id="problem-formulation">Problem Formulation</h3> <p>This method uses an energy optimization perspective instead of relying on a surrogate model. By formulating this way, the method address a key issue with existing inverse design approaches, where the optimization process can easily fall out-of-distribution of the distribution of the design parameters seen during training.</p> <p>This approach jointly optimize the design objective \(\mathcal J\) and a generative objective \(E_\theta\),</p> \[\dot\gamma = \underset{\dot\gamma,U_{[0,T]}}{\arg\min}\, [E_\theta (U_{[0,T]}, \gamma] + \lambda \mathcal J (U_{[0,T]}, \gamma) ],\] <p>where \(E_\theta\) is an energy-based model (EBM) <d-cite key="lecun2006energy"></d-cite> <d-cite key="du2019energy"></d-cite>, trained over joined distribution of trajectories \(U_{[0,T]}\) (discrete version of \(u\) as we don’t have access to ground-truth model for dynamical system) and boundaries \(\gamma\) and \(\lambda\) is hyperparameter balancing the two objectives.</p> <p>We also need training loss to that used to train energy-based model $E_\theta$ using a diffusion objective.</p> \[L_{\text{MSE}} = \| \epsilon - \epsilon_{\theta}(\sqrt{1-\beta_s} z + \sqrt{\beta_s} \epsilon, s) \|_2^2, \quad \epsilon \sim \mathcal{N}(0, I),\] <p>where:</p> <ul> <li>\(\epsilon_{\theta}\) is the denoising network</li> <li>\(z\) represents all variables in the design optimization (\(z = U_{[0, T]} ⊕ \gamma\))</li> <li>\(s\) is the diffusion step</li> <li>\(\beta_s\) is a noise schedule parameter</li> <li>\(\epsilon\) is Gaussian noise</li> </ul> <p>The following equation represents a step in the Langevin sampling process used in the optimization <d-cite key="du2023langevin"></d-cite>. It iteratively updates the optimization variable \(z\) to minimize the combined objective.</p> \[z_{s-1} = z_s - \eta (\nabla_z (E_\theta(z_s) + \lambda J(z_s))) + \xi, \quad \xi \sim \mathcal{N}(0, \sigma_s^2 I),\] <p>Where:</p> <ul> <li>\(z_s\)​: Current optimization variable.</li> <li>\(\eta\): Step size.</li> <li>\(E_\theta\)​: Energy function modeling the system.</li> <li>\(J(z_s)\): Design objective.</li> <li>\(\lambda\): Hyperparameter weighting J(zs)J(z_s)J(zs​).</li> <li>\(\xi\): Gaussian noise added to explore the space.</li> </ul> <h3 id="compositional-generative-inverse-design">Compositional Generative Inverse Design</h3> <p>The method enables generalization to more complex scenarios by composing energy functions \(E_\theta\)​ defined over subsets of the design variables \(z\). Each subset enforces local physical consistency while their overlap ensures global consistency.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/cindm-480.webp 480w,/assets/img/2025-02-10-cindm/cindm-800.webp 800w,/assets/img/2025-02-10-cindm/cindm-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/cindm.png" class="cindm" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 4 CinDM framework</figcaption> </figure> <p>Only energy function \(E_\theta\) will be optimized during training. However, during inference time, both objective \(J(z_s)\) and energy function \(E_\theta\) will be optimized together.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/cindm-method-intuition-480.webp 480w,/assets/img/2025-02-10-cindm/cindm-method-intuition-800.webp 800w,/assets/img/2025-02-10-cindm/cindm-method-intuition-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/cindm-method-intuition.png" class="cindm-intuition" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 5 An intuition about getting an unique solution by considering Design Objectives during inference</figcaption> </figure> <p>The pseudo algorithm is given as:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Compositional Inverse Design with Diffusion Models (CinDM)
# Input: Diffusion models {ϵ_iθ}, design objective J(·), hyperparameters λ, S, K
# Output: Optimized design variables γ and trajectory U[0,T]
</span>
<span class="n">initialize</span> <span class="n">z_S</span> <span class="err">∼</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>  <span class="c1"># Random initialization
</span>
<span class="c1"># Optimize across diffusion steps S
</span><span class="k">for</span> <span class="n">s</span> <span class="o">=</span> <span class="n">S</span><span class="p">,</span> <span class="p">...,</span> <span class="mi">1</span><span class="p">:</span>
    <span class="c1"># Langevin sampling steps at step s
</span>    <span class="k">for</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="p">...,</span> <span class="n">K</span><span class="p">:</span>
        <span class="n">ξ</span> <span class="err">∼</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">σ_s</span><span class="o">^</span><span class="mi">2</span> <span class="n">I</span><span class="p">)</span>  <span class="c1"># Sample Gaussian noise
</span>        <span class="n">z_s</span> <span class="err">←</span> <span class="n">z_s</span> <span class="o">-</span> <span class="n">η</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">Σ_i</span> <span class="p">[</span><span class="n">ϵ_iθ</span><span class="p">(</span><span class="n">z_s</span><span class="o">^</span><span class="n">i</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="n">λ</span> <span class="err">∇</span><span class="n">z</span> <span class="nc">J</span><span class="p">(</span><span class="n">z_s</span><span class="p">)]</span> <span class="o">+</span> <span class="n">ξ</span>
    
    <span class="n">ξ</span> <span class="err">∼</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">σ_s</span><span class="o">^</span><span class="mi">2</span> <span class="n">I</span><span class="p">)</span>  <span class="c1"># Noise for next diffusion step
</span>    <span class="n">z_s</span><span class="o">-</span><span class="mi">1</span> <span class="err">←</span> <span class="n">z_s</span> <span class="o">-</span> <span class="n">η</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">Σ_i</span> <span class="p">[</span><span class="n">ϵ_iθ</span><span class="p">(</span><span class="n">z_s</span><span class="o">^</span><span class="n">i</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="n">λ</span> <span class="err">∇</span><span class="n">z</span> <span class="nc">J</span><span class="p">(</span><span class="n">z_s</span><span class="p">)]</span> <span class="o">+</span> <span class="n">ξ</span>

<span class="k">return</span> <span class="n">γ</span><span class="p">,</span> <span class="n">U</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">T</span><span class="p">]</span> <span class="o">=</span> <span class="n">z_0</span>  <span class="c1"># Return optimized results
</span>
</code></pre></div></div> <h3 id="experiments">Experiments</h3> <p>The study rigorously evaluates CinDM’s ability to generalize across three distinct axes: (1) system complexity, synthesizing configurations with components exceeding training data scales; (2) unseen constraints, adapting to novel physical or geometric requirements not encoded during training; and (3) cross-domain adaptability, transferring learned priors to disparate design problems. These experiments collectively demonstrate how compositional energy guidance in diffusion models enables scalable robustness, outperforming monolithic architectures in handling out-of-distribution challenges.</p> <h4 id="1-generalization-to-longer-time-steps"><strong>1. Generalization to Longer Time Steps</strong>:</h4> <ul> <li>Trajectories are split into overlapping intervals during training.</li> <li>At test time, the model combines these intervals to generate longer rollouts (e.g., 34, 44, or 54 steps).</li> <li>This enables accurate design for systems evolving over extended time horizons.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/exp1-int-480.webp 480w,/assets/img/2025-02-10-cindm/exp1-int-800.webp 800w,/assets/img/2025-02-10-cindm/exp1-int-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/exp1-int.png" class="exp1-int" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 6 Different time steps during training and inference</figcaption> </figure> <p>CinDM significantly outperformed baselines (CEM <d-cite key="rubinstein2004simulation"></d-cite>, Backprop <d-cite key="allen2022inverse"></d-cite>) in both <strong>trajectory accuracy</strong> (MAE) and <strong>design objectives</strong>.</p> <h4 id="2-generalization-to-more-interacting-objects"><strong>2. Generalization to More Interacting Objects</strong>:</h4> <ul> <li>Pairwise energy functions learned from smaller systems (e.g., 2-body interactions) are composed to model larger systems (e.g., 4-body or 8-body).</li> <li>This allows CinDM to scale and handle more complex dynamics with many interacting entities.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/exp2-int-480.webp 480w,/assets/img/2025-02-10-cindm/exp2-int-800.webp 800w,/assets/img/2025-02-10-cindm/exp2-int-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/exp2-int.png" class="exp2-int" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Fig 7 gives Different state composition duringtraining and inference</figcaption> </figure> <p>CinDM excelled at scaling to systems with more interacting bodies (4-body and 8-body), outperforming baselines in both accuracy and design objectives.</p> <table> <thead> <tr> <th style="text-align: left">Method</th> <th style="text-align: center">4-body, 24 steps (MAE ↓)</th> <th style="text-align: center">4-body, 44 steps (MAE ↓)</th> <th style="text-align: center">8-body, 24 steps (MAE ↓)</th> <th style="text-align: center">8-body, 44 steps (MAE ↓)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Backprop, GNS (1-step)</td> <td style="text-align: center">0.06008</td> <td style="text-align: center">0.30416</td> <td style="text-align: center">0.46541</td> <td style="text-align: center">0.72814</td> </tr> <tr> <td style="text-align: left"><strong>CinDM (Ours)</strong></td> <td style="text-align: center"><strong>0.03928</strong></td> <td style="text-align: center"><strong>0.03163</strong></td> <td style="text-align: center"><strong>0.09241</strong></td> <td style="text-align: center"><strong>0.09249</strong></td> </tr> </tbody> </table> <h4 id="3-generalization-from-parts-to-whole-for-boundaries"><strong>3. Generalization from Parts to Whole for Boundaries</strong>:</h4> <ul> <li>Design variables (e.g., shapes) are decomposed into parts during training, with individual energy functions for each part.</li> <li>At test time, the parts are composed into a whole system (e.g., multi-part structures like planes or airfoils).</li> <li>This supports designing more complex systems by leveraging local consistency across parts.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/experiment2-480.webp 480w,/assets/img/2025-02-10-cindm/experiment2-800.webp 800w,/assets/img/2025-02-10-cindm/experiment2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/experiment2.png" class="experiment3" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">fig 8 Different boundary conditions during inference</figcaption> </figure> <p>CinDM showed superior performance in terms of <strong>lift-to-drag ratio</strong> and design objective compared to other methods. It also discovered <strong>formation flying</strong>, reducing drag and increasing efficiency.</p> <table> <thead> <tr> <th style="text-align: left">Method</th> <th style="text-align: center">1 Airfoil (Lift-to-Drag Ratio ↑)</th> <th style="text-align: center">2 Airfoils (Lift-to-Drag Ratio ↑)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">CEM, FNO</td> <td style="text-align: center">1.4005</td> <td style="text-align: center">1.0914</td> </tr> <tr> <td style="text-align: left">Backprop, FNO</td> <td style="text-align: center">1.3300</td> <td style="text-align: center">0.9722</td> </tr> <tr> <td style="text-align: left"><strong>CinDM (Ours)</strong></td> <td style="text-align: center"><strong>2.1770</strong></td> <td style="text-align: center"><strong>1.4216</strong></td> </tr> </tbody> </table> <p>Here are the visual representation of generation process and generated example</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/generation_process-480.webp 480w,/assets/img/2025-02-10-cindm/generation_process-800.webp 800w,/assets/img/2025-02-10-cindm/generation_process-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/generation_process.gif" class="gen-process" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">fig 9 Generation Process</figcaption> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-10-cindm/generated_examples-480.webp 480w,/assets/img/2025-02-10-cindm/generated_examples-800.webp 800w,/assets/img/2025-02-10-cindm/generated_examples-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-10-cindm/generated_examples.gif" class="gen-example" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">fig 10 Generated Example</figcaption> </figure> <h2 id="conclusion">Conclusion</h2> <p>The authors conclude that the Compositional Inverse Design with Diffusion Models (CinDM) method offers a novel and effective approach to compositional generative inverse design. This conclusion stems from CinDM’s ability to compose trained diffusion models, focusing on subsets of design variables, and jointly optimize trajectories and boundaries. This allows CinDM to generalize and design systems of greater complexity than those encountered during training.</p> <h3 id="key-takeaways">Key takeaways</h3> <ul> <li><strong>Compositionality is key</strong>: CinDM’s ability to compose diffusion models trained on simpler design components enables it to tackle more complex systems at test time. This is highlighted by its successful generalization to longer time horizons, systems with more interacting objects, and the design of complex 2D airfoil shapes.</li> <li><strong>Generative approach for robust design</strong>: By framing inverse design as an energy optimization problem within a generative framework, CinDM encourages physically consistent designs and avoids falling into adversarial modes, as observed in some baseline methods.</li> <li><strong>Wide applicability</strong>: The authors believe that the CinDM approach can be applied to a wide range of inverse design problems beyond the examples presented in the sources. They suggest its potential use in material design, drug discovery, and molecule design.</li> </ul> <h3 id="ongoing-challenges">Ongoing Challenges</h3> <ul> <li><strong>Complex Design Space</strong>: Real-world design problems often involve complex systems with many components that can be combined in various ways. For example, in rocket design, the system includes an airframe, propulsion, and payload, each consisting of hundreds of parts. Representing and optimizing such a complex design space is a significant challenge.</li> <li><strong>Conflicting Objectives</strong>: Engineering designs usually involve multiple objectives that can conflict with each other. For instance, in designing a phone battery, we want it to be both long-lasting and lightweight, but these goals often oppose each other, requiring a balanced solution.</li> <li><strong>Changing Importance of Objectives</strong>: The importance of different objectives can change depending on the situation. For example, during a rocket launch, air resistance, fuel efficiency, and structural durability have different levels of importance as the rocket moves from the ground to space, creating varying optimization priorities.</li> </ul> <h3 id="remarks">Remarks</h3> <p>In their paper “Compositional Generative Inverse Design,” Wu et al. introduce a novel approach to inverse design through the use of compositional generative models, leveraging diffusion-based energy functions for optimization. The key contributions of this work are the introduction of a generative perspective to avoid adversarial design and the ability to generalize to more complex and unseen design scenarios, such as longer time steps and systems with more interacting components. The method enables efficient optimization without relying on autoregressive rollouts, and its compositional nature allows for the design of complex systems, like multi-airfoil configurations, by combining simpler learned models. Additionally, the approach introduces a compositional framework that can be applied to a wide range of design tasks, significantly enhancing the flexibility and performance of inverse design solutions.</p>]]></content><author><name>[{&quot;name&quot;=&gt;&quot;Manthan Solanki&quot;, &quot;url&quot;=&gt;&quot;https://manthan2305.github.io/&quot;, &quot;affiliations&quot;=&gt;{&quot;name&quot;=&gt;&quot;Stuttgart University, Germany&quot;}}]</name></author><category term="generative-ai"/><category term="diffusion-models"/><category term="composition"/><category term="inverse-design"/><summary type="html"><![CDATA[Recent advancements in the field of neural partial differential equation (PDE) solvers have revolutionized the design paradigm in engineering, particularly in the inverse design approach. The paper Compositional Generative Inverse Design by Wu et al., published in ICLR 2024, revisits the compositional inverse design using diffusion models. This approach outperforms both state-of-the-art generative models and classical PDE solvers by generating plausible and unique designs. This blog post explores the key contributions of this work, focusing on the strategies used to address the common problem of over-optimization and physically implausible design generation.]]></summary></entry></feed>